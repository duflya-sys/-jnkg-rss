import os
import sys
import pandas as pd
from datetime import datetime
import time

# å°†å½“å‰ç›®å½•åŠ å…¥è·¯å¾„ï¼Œç¡®ä¿èƒ½å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
try:
    from spider_core import JnkgBiddingSpider
    from feishu_writer import FeishuBitableWriter
    from feishu_notifier import FeishuNotifier
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å—å¤±è´¥ï¼Œè¯·ç¡®ä¿ç›¸å…³.pyæ–‡ä»¶åœ¨å½“å‰ç›®å½•: {e}")
    sys.exit(1)

def get_feishu_config():
    """ä»ç¯å¢ƒå˜é‡è·å–é£ä¹¦é…ç½®ï¼ˆå®‰å…¨ï¼‰"""
    config = {
        'app_id': os.getenv('FEISHU_APP_ID'),
        'app_secret': os.getenv('FEISHU_APP_SECRET'),
        'app_token': os.getenv('FEISHU_APP_TOKEN'),
        'table_id': os.getenv('FEISHU_TABLE_ID'),
        'webhook_url': os.getenv('FEISHU_WEBHOOK_URL')
    }
    
    # æ¸…ç†å¯èƒ½çš„å¤šä½™å­—ç¬¦
    if config['app_token'] and '&' in config['app_token']:
        config['app_token'] = config['app_token'].split('&')[0]
    
    if config['table_id'] and '&' in config['table_id']:
        config['table_id'] = config['table_id'].split('&')[0]
    
    # æ£€æŸ¥å…³é”®é…ç½®æ˜¯å¦å­˜åœ¨
    missing = [k for k, v in config.items() if not v and k != 'webhook_url']
    if missing:
        print(f"âš ï¸  è­¦å‘Šï¼šä»¥ä¸‹é£ä¹¦é…ç½®ç¼ºå¤±: {missing}")
        return None
    
    print(f"ğŸ”§ é£ä¹¦é…ç½®è¯¦æƒ…:")
    print(f"   App ID: {config['app_id'][:10]}..." if config['app_id'] else "   App ID: æœªè®¾ç½®")
    print(f"   App Token: {config['app_token']}")
    print(f"   Table ID: {config['table_id']}")
    print(f"   Webhook URL: {'å·²è®¾ç½®' if config['webhook_url'] else 'æœªè®¾ç½®'}")
    
    return config
# åœ¨main.pyä¸­æ·»åŠ ä»£ç†æµ‹è¯•å‡½æ•°
def test_network_connectivity():
    """æµ‹è¯•ç½‘ç»œè¿é€šæ€§"""
    print("ğŸ” æµ‹è¯•ç½‘ç»œè¿é€šæ€§...")
    
    # æ£€æŸ¥æ˜¯å¦åœ¨GitHub Actionsç¯å¢ƒ
    is_github = os.getenv('GITHUB_ACTIONS') == 'true'
    print(f"GitHub Actionsç¯å¢ƒ: {is_github}")
    
    if is_github:
        print("ğŸŒ æ£€æµ‹åˆ°GitHub Actionsç¯å¢ƒï¼Œå°†å¯ç”¨ä»£ç†")
        print("ä»£ç†åœ°å€: http://117.69.236.166:8089")
    
    # å¯¼å…¥ä»£ç†æµ‹è¯•
    try:
        from proxy_test import test_proxy
        test_proxy()
    except ImportError:
        print("âš ï¸  ä»£ç†æµ‹è¯•æ¨¡å—æœªæ‰¾åˆ°ï¼Œè·³è¿‡æµ‹è¯•")

# åœ¨run_full_processå‡½æ•°å¼€å¤´æ·»åŠ 
def run_full_process(days_limit=10):
    """å®Œæ•´çš„æŠ“å–å’Œä¸Šä¼ æµç¨‹"""
    print("="*60)
    print(f"å¼€å§‹æ‰§è¡Œæ™‹èƒ½æ§è‚¡æ‹›æ ‡æ•°æ®æŠ“å–ä»»åŠ¡")
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)
    
    # ç½‘ç»œæµ‹è¯•
    test_network_connectivity()

def run_full_process(days_limit=10):
    """å®Œæ•´çš„æŠ“å–å’Œä¸Šä¼ æµç¨‹"""
    print("="*60)
    print(f"å¼€å§‹æ‰§è¡Œæ™‹èƒ½æ§è‚¡æ‹›æ ‡æ•°æ®æŠ“å–ä»»åŠ¡")
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)
    
    # 1. åˆå§‹åŒ–çˆ¬è™«å¹¶æŠ“å–æ•°æ®
    print("\nğŸ” æ­¥éª¤1: å¼€å§‹æŠ“å–æ‹›æ ‡æ•°æ®...")
    spider = JnkgBiddingSpider()
    
    # ä½¿ç”¨æ–°çš„å¤šç½‘ç«™æœç´¢æ–¹æ³•
    all_data = spider.search_all_websites(days_limit=days_limit)
    
    if not all_data:
        print("æœ¬æ¬¡æœªæŠ“å–åˆ°ç¬¦åˆæ¡ä»¶çš„æ•°æ®ã€‚ä»»åŠ¡ç»“æŸã€‚")
        # å°è¯•å‘é€ç©ºæ•°æ®é€šçŸ¥ï¼ˆå¦‚æœé…ç½®äº†webhookï¼‰
        feishu_config = get_feishu_config()
        if feishu_config and feishu_config.get('webhook_url'):
            try:
                notifier = FeishuNotifier(feishu_config['webhook_url'])
                notifier.send_text("ğŸ•·ï¸ æ‹›æ ‡æ•°æ®æŠ“å–å®Œæˆ\n\næœ¬æ¬¡æœªæŠ“å–åˆ°ç¬¦åˆæ¡ä»¶çš„æ•°æ®ã€‚")
            except Exception as e:
                print(f"å‘é€ç©ºæ•°æ®é€šçŸ¥å¤±è´¥: {e}")
        return False, 0, 0, 0
    
    df = pd.DataFrame(all_data)
    print(f"âœ… æŠ“å–å®Œæˆï¼Œå…±è·å¾— {len(df)} æ¡å”¯ä¸€æ•°æ®ã€‚")
    
    # 2. ä¸Šä¼ åˆ°é£ä¹¦å¤šç»´è¡¨æ ¼
    print("\nğŸ“¤ æ­¥éª¤2: å‡†å¤‡ä¸Šä¼ æ•°æ®åˆ°é£ä¹¦å¤šç»´è¡¨æ ¼...")
    feishu_config = get_feishu_config()
    
    if not feishu_config:
        print("ç”±äºé£ä¹¦é…ç½®ä¸å…¨ï¼Œè·³è¿‡ä¸Šä¼ æ­¥éª¤ã€‚")
        # æœ¬åœ°ä¿å­˜ä¸€ä»½CSVä½œä¸ºå¤‡ä»½
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        csv_file = f"æœ¬åœ°å¤‡ä»½_æ™‹èƒ½æ§è‚¡æ‹›æ ‡_{timestamp}.csv"
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        print(f"æ•°æ®å·²æœ¬åœ°å¤‡ä»½è‡³: {csv_file}")
        return True, len(df), 0, 0
    
    try:
        # åˆå§‹åŒ–é£ä¹¦å†™å…¥å™¨
        writer = FeishuBitableWriter(
            app_id=feishu_config['app_id'],
            app_secret=feishu_config['app_secret'],
            app_token=feishu_config['app_token'],
            table_id=feishu_config['table_id'],
            debug=True
        )
        
        # ä¸Šä¼ æ•°æ®ï¼Œä½¿ç”¨'é¡¹ç›®ç¼–å·'ä½œä¸ºå»é‡ä¾æ®
        success, fail, duplicate = writer.add_records(df, unique_key_field='é¡¹ç›®ç¼–å·')
        
        print("\nğŸ“Š ä¸Šä¼ ç»“æœæ±‡æ€»:")
        print(f"   æˆåŠŸæ–°å¢: {success} æ¡")
        print(f"   é‡å¤è·³è¿‡: {duplicate} æ¡")
        print(f"   æ·»åŠ å¤±è´¥: {fail} æ¡")
        
        # 3. æœ¬åœ°ä¹Ÿä¿å­˜ä¸€ä»½CSVä½œä¸ºå¤‡ä»½
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        csv_file = f"æ™‹èƒ½æ§è‚¡æ‹›æ ‡_{timestamp}.csv"
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        print(f"ğŸ“ æ•°æ®å·²å¤‡ä»½è‡³æœ¬åœ°æ–‡ä»¶: {csv_file}")
        
        # 4. å‘é€é£ä¹¦æœºå™¨äººæé†’ï¼ˆå¦‚æœé…ç½®äº†webhookï¼‰
        if feishu_config.get('webhook_url'):
            print("\nğŸ“¨ æ­¥éª¤3: å‘é€é£ä¹¦æœºå™¨äººæé†’...")
            try:
                notifier = FeishuNotifier(feishu_config['webhook_url'])
                # ä½¿ç”¨å¡ç‰‡æ¶ˆæ¯æ ¼å¼
                report = notifier.send_crawler_report_with_card(
                    total_count=len(df),
                    success_count=success,
                    duplicate_count=duplicate,
                    fail_count=fail
                )
                if report and report.get("StatusCode") == 0:
                    print("âœ… é£ä¹¦æœºå™¨äººå¡ç‰‡æé†’å‘é€æˆåŠŸï¼")
                else:
                    # å¦‚æœå¡ç‰‡æ¶ˆæ¯å¤±è´¥ï¼Œå°è¯•æ™®é€šæ–‡æœ¬æ¶ˆæ¯
                    print(f"âš ï¸  å¡ç‰‡æ¶ˆæ¯å‘é€å¤±è´¥ï¼Œå°è¯•æ–‡æœ¬æ¶ˆæ¯...")
                    report = notifier.send_crawler_report(
                        total_count=len(df),
                        success_count=success,
                        duplicate_count=duplicate,
                        fail_count=fail
                    )
                    if report and report.get("StatusCode") == 0:
                        print("âœ… é£ä¹¦æœºå™¨äººæ–‡æœ¬æé†’å‘é€æˆåŠŸï¼")
                    else:
                        print(f"âš ï¸  é£ä¹¦æœºå™¨äººæé†’å‘é€å¤±è´¥ï¼Œå“åº”: {report}")
            except Exception as e:
                print(f"âŒ å‘é€é£ä¹¦æœºå™¨äººæé†’æ—¶å‡ºé”™: {e}")
        else:
            print("\nâ„¹ï¸  æœªé…ç½®é£ä¹¦Webhook URLï¼Œè·³è¿‡é€šçŸ¥æ­¥éª¤")
        
        return True, len(df), success, duplicate
        
    except Exception as e:
        print(f"âŒ ä¸Šä¼ åˆ°é£ä¹¦è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        # å‡ºé”™æ—¶ä¹Ÿä¿å­˜æœ¬åœ°å¤‡ä»½
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        csv_file = f"é”™è¯¯å¤‡ä»½_æ™‹èƒ½æ§è‚¡æ‹›æ ‡_{timestamp}.csv"
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        print(f"æ•°æ®å·²ä¿å­˜è‡³æœ¬åœ°å¤‡ä»½æ–‡ä»¶: {csv_file}")
        
        # é”™è¯¯æ—¶ä¹Ÿå‘é€æé†’ï¼ˆå¦‚æœé…ç½®äº†webhookï¼‰
        if feishu_config and feishu_config.get('webhook_url'):
            try:
                notifier = FeishuNotifier(feishu_config['webhook_url'])
                error_msg = f"âŒ æ‹›æ ‡æ•°æ®æŠ“å–ä»»åŠ¡å¤±è´¥\n\né”™è¯¯æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\né”™è¯¯è¯¦æƒ…: {str(e)}"
                notifier.send_text(error_msg)
                print("âœ… é”™è¯¯é€šçŸ¥å·²å‘é€è‡³é£ä¹¦ã€‚")
            except Exception as notify_error:
                print(f"âŒ å‘é€é”™è¯¯é€šçŸ¥ä¹Ÿå¤±è´¥äº†: {notify_error}")
            
        return False, len(df), 0, 0

if __name__ == "__main__":
    """
    ä¸»å…¥å£ã€‚
    å½“ç›´æ¥è¿è¡Œæ­¤è„šæœ¬æ—¶ï¼Œæ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„æŠ“å–å’Œä¸Šä¼ ã€‚
    æ­¤è„šæœ¬ä¹Ÿå¯è¢« GitHub Actions æˆ– APScheduler è°ƒç”¨ã€‚
    """
    # æ‰§è¡Œå®Œæ•´çš„æŠ“å–ä¸Šä¼ æµç¨‹ï¼ˆé»˜è®¤æŸ¥æœ€è¿‘10å¤©ï¼‰
    run_full_process(days_limit=10)
